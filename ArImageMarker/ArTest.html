<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>chapter 3, brief matching</title>
    <script src="./js/tracking-min.js"></script>
    <script src="./js/jsfeat-min.js"></script>
    <script src="./js/common-jsfeat.js"></script>
    <script src="./js/oflow.js"></script>
    <link rel="stylesheet" type="text/css" href="css/cvw.css">
    
    <style>
        #container {
            position: relative;
        }
        #overlay {
            position: absolute;
            top: 0;
            left: 0;
            z-index: 10;
            background-color:rgba(255,0,0,0);
        }
        .button {
            background-color: #4CAF50;
            border: none;
            color: white;
            padding: 200px 200px;
            text-align: center;
            font-size: 16px;
            cursor: pointer;
        }

        .button:hover {
            background-color: green;
        }
    </style>
</head>
<body>

<div id="images" class="canvas-parent">
    <div id="container">
        <video id='video' width='960px' height='540px' autoplay loop muted>
            <source src="../resources/bonchon_ads_video.mp4">
        </video>
        <canvas id="overlay" width='960px' height='540px'></canvas>
    </div>
    <canvas id="initCanvas" class="canvas-img"></canvas>
    <canvas id="vcanvas" width="960px" height="540px"></canvas>
    <canvas id='flow' width='960px' height='540px'></canvas>
</div>

<button class="button" onclick="webCamFlow.startCapture();video.play();">PLAY</button>

<script>

    // ------------------------------------------------------------------------
    // ------------------------------------------------------------------------
    // Feature matching
    // ------------------------------------------------------------------------
    // ------------------------------------------------------------------------

    var canvas = document.getElementById('initCanvas'),
            imageObject = new Image(), colsObject, rowsObject,
            imageScene = new Image(), colsScene, rowsScene;

    imageScene.src = '../resources/bonchon_ads.png'; // Don't use this
    imageObject.src = '../resources/bonchon_ads.png';

    var homo3x3 = new jsfeat.matrix_t(3, 3, jsfeat.F32C1_t);
    var match_mask = new jsfeat.matrix_t(500, 1, jsfeat.U8C1_t);

    function find_transform(matches, count) {
        // motion kernel
        var mm_kernel = new jsfeat.motion_model.homography2d();
        // ransac params
        var num_model_points = 4;
        var reproj_threshold = 3;
        var ransac_param = new jsfeat.ransac_params_t(num_model_points,
                reproj_threshold, 0.5, 0.99);

        var pattern_xy = [];
        var screen_xy = [];

        // construct correspondences
        for (var i = 0; i < count; ++i) {
            var m = matches[i];
            pattern_xy[i] = {"x": m.keypoint1[0], "y": m.keypoint1[1]};
            screen_xy[i] = {"x": m.keypoint2[0], "y": m.keypoint2[1]};
        }

        // estimate motion
        var ok = false;
        ok = jsfeat.motion_estimator.ransac(ransac_param, mm_kernel,
                pattern_xy, screen_xy, count, homo3x3, match_mask, 1000);

        var pattern_xy2 = [];
        var screen_xy2 = [];
        // extract good matches and re-estimate
        var good_cnt = 0;
        if (ok) {
            for (var i = 0; i < count; ++i) {
                if (match_mask.data[i]) {
                    pattern_xy2[good_cnt] = {"x": pattern_xy[i].x, "y": pattern_xy[i].y};
                    screen_xy2[good_cnt] = {"x": screen_xy[i].x, "y": screen_xy[i].y};
                    good_cnt++;
                }
            }
            // run kernel directly with inliers only
            mm_kernel.run(pattern_xy2, screen_xy2, homo3x3, good_cnt);
        } else {
            jsfeat.matmath.identity_3x3(homo3x3, 1.0);
        }

        return good_cnt;
    }

    function tCorners(M, w, h) {
        var pt = [{'x': 0, 'y': 0}, {'x': w, 'y': 0}, {'x': w, 'y': h}, {'x': 0, 'y': h}];
        var z = 0.0, i = 0, px = 0.0, py = 0.0;

        for (; i < 4; ++i) {
            px = M[0] * pt[i].x + M[1] * pt[i].y + M[2];
            py = M[3] * pt[i].x + M[4] * pt[i].y + M[5];
            z = M[6] * pt[i].x + M[7] * pt[i].y + M[8];
            pt[i].x = px / z;
            pt[i].y = py / z;
        }

        return pt;
    }

    function getAngle(p0x, p0y, p1x, p1y, p2x, p2y) {

        vec0x = p1x - p0x;
        vec0y = p1y - p0y;
        vec1x = p2x - p1x;
        vec1y = p2y - p1y;

        val0 = vec0x*vec1x + vec0y*vec1y;

        distVec0 = Math.sqrt(vec0x*vec0x + vec0y*vec0y);
        distVec1 = Math.sqrt(vec1x*vec1x + vec1y*vec1y);
        val1 = distVec0 * distVec1;

        cosVal = val0 / val1;

        return Math.abs(Math.acos(cosVal));
    }

    // C* cluster
    var boundX0, boundX1, boundX2, boundX3;
    var boundY0, boundY1, boundY2, boundY3;

    // C+ cluster
    var bound2X0, bound2X1, bound2X2, bound2X3;
    var bound2Y0, bound2Y1, bound2Y2, bound2Y3;

    function check_accurate_cluster(cts, shift) {

        var shape_pts = tCorners(homo3x3.data, colsObject, rowsObject);

        var ow = imageObject.width*imageObject.width;
        var oh = imageObject.height*imageObject.height;
        
        // Get all angles
        var a0 = getAngle(shape_pts[0].x + shift, shape_pts[0].y, 
                            shape_pts[1].x + shift, shape_pts[1].y,
                            shape_pts[2].x + shift, shape_pts[2].y);
        var a1 = getAngle(shape_pts[1].x + shift, shape_pts[1].y, 
                            shape_pts[2].x + shift, shape_pts[2].y,
                            shape_pts[3].x + shift, shape_pts[3].y);
        var a2 = getAngle(shape_pts[2].x + shift, shape_pts[2].y, 
                            shape_pts[3].x + shift, shape_pts[3].y,
                            shape_pts[0].x + shift, shape_pts[0].y);
        //var a3 = getAngle(shape_pts[3].x + shift, shape_pts[3].y, shape_pts[0].x + shift, shape_pts[0].y); // Not necessary

        // Get satisfy rectangle by angles
        var DIF_THRES = 7.0 * Math.PI / 180.0;
        var PERFECT_ANGLE = 90.0 * Math.PI / 180.0;
        var MIN_ANGLE_THRES = PERFECT_ANGLE - DIF_THRES;
        var MAX_ANGLE_THRES = PERFECT_ANGLE + DIF_THRES;

        if (shape_pts[0].x != 0 && shape_pts[0].y != 0 &&
            shape_pts[1].x != 0 && shape_pts[1].y != 0 &&
            shape_pts[2].x != 0 && shape_pts[2].y != 0 &&
            shape_pts[3].x != 0 && shape_pts[3].y != 0
            &&
            a0 >= MIN_ANGLE_THRES && a0 <= MAX_ANGLE_THRES &&
            a1 >= MIN_ANGLE_THRES && a1 <= MAX_ANGLE_THRES &&
            a2 >= MIN_ANGLE_THRES && a2 <= MAX_ANGLE_THRES) {

            boundX0 = shape_pts[0].x;
            boundY0 = shape_pts[0].y;
            boundX1 = shape_pts[1].x;
            boundY1 = shape_pts[1].y;
            boundX2 = shape_pts[2].x;
            boundY2 = shape_pts[2].y;
            boundX3 = shape_pts[3].x;
            boundY3 = shape_pts[3].y;

            // Apply to C+ cluster (reset)
            bound2X0 = boundX0;
            bound2X1 = boundX1;
            bound2X2 = boundX2;
            bound2X3 = boundX3;

            bound2Y0 = boundY0;
            bound2Y1 = boundY1;
            bound2Y2 = boundY2;
            bound2Y3 = boundY3;
        }
    }

    // Render the latest satisfy shape here
    function renderSatisfyPatternShaper(context, offset) {

        context.strokeStyle = "rgb(255,0,0)";
        context.beginPath();

        context.moveTo(boundX0 + offset, boundY0);
        context.lineTo(boundX1 + offset, boundY1);
        context.lineTo(boundX2 + offset, boundY2);
        context.lineTo(boundX3 + offset, boundY3);
        context.lineTo(boundX0 + offset, boundY0);

        context.lineWidth = 4;
        context.stroke();
    }

    function renderSmoothShape(context) {

        context.strokeStyle = "rgb(0,0,255)";
        context.beginPath();

        context.moveTo(bound2X0, bound2Y0);
        context.lineTo(bound2X1, bound2Y1);
        context.lineTo(bound2X2, bound2Y2);
        context.lineTo(bound2X3, bound2Y3);
        context.lineTo(bound2X0, bound2Y0);

        context.lineWidth = 4;
        context.stroke();
    }

    function render_pattern_shape(ctx, shift) {

        // get the projected pattern corners
        var shape_pts = tCorners(homo3x3.data, colsObject, rowsObject);

        ctx.strokeStyle = "rgb(0,255,0)";
        ctx.beginPath();

        ctx.moveTo(shape_pts[0].x + shift, shape_pts[0].y);
        ctx.lineTo(shape_pts[1].x + shift, shape_pts[1].y);
        ctx.lineTo(shape_pts[2].x + shift, shape_pts[2].y);
        ctx.lineTo(shape_pts[3].x + shift, shape_pts[3].y);
        ctx.lineTo(shape_pts[0].x + shift, shape_pts[0].y);
        
        ctx.lineWidth = 4;
        ctx.stroke();

        var p0x = shape_pts[0].x + shift;
        var p0y = shape_pts[0].y;
        var p1x = shape_pts[1].x + shift;
        var p1y = shape_pts[1].y;
        var p2x = shape_pts[2].x + shift;
        var p2y = shape_pts[2].y;
        var p3x = shape_pts[3].x + shift;
        var p3y = shape_pts[3].y;
    }

    // Optical flow

    var zoneSize = 16;
    var videoElement = document.getElementById('video');
    var webCamFlow = new oflow.VideoFlow(videoElement, zoneSize);

    runOpticalFlow = function() {

        var flowCanvas = document.getElementById('flow'),
                flowContext = flowCanvas.getContext('2d'),
                sceneWidth = flowCanvas.width,
                sceneHeight = flowCanvas.height;
        
        // http://stackoverflow.com/questions/8211745/draw-an-arrow-on-html5-canvas-between-two-objects
        function drawArrow(ctx, p1, p2, size) {
            ctx.save();

            // Rotate the context to point along the path
            var dx = p2.x - p1.x, dy = p2.y - p1.y, len = Math.sqrt(dx * dx + dy * dy);
            ctx.translate(p2.x, p2.y);
            ctx.rotate(Math.atan2(dy, dx));

            ctx.lineWidth = 3;
            // line
            ctx.beginPath();
            ctx.moveTo(0, 0);
            ctx.lineTo(-len, 0);
            ctx.closePath();
            ctx.stroke();

            // arrowhead
            ctx.beginPath();
            ctx.moveTo(0, 0);
            ctx.lineTo(-size, -size);
            ctx.lineTo(-size, size);
            ctx.closePath();
            ctx.fill();

            ctx.restore();
        }

        webCamFlow.onCalculated(function (direciton) {
            
            flowContext.clearRect(0, 0, sceneWidth, sceneHeight);
            flowContext.strokeStyle = "rgb(0,0,0)";

            // Calculate C+ offset from arrow
            var offsetX = 0;
            var offsetY = 0;

            /* // render zones
            for (var i = 0; i < direciton.zones.length; ++i) {
                var zone = direciton.zones[i];
                drawArrow(flowContext, zone, {x: zone.x + zone.u * 4, y: zone.y + zone.v * 4}, 5);
            }
            /*/ // render zones if inbound
            for (var i = 0; i < direciton.zones.length; ++i) {
                var zone = direciton.zones[i];
                if (zone.x < bound2X0 || zone.x < bound2X3 ||
                    zone.x > bound2X1 || zone.x > bound2X2)
                    continue;
                if (zone.y < boundY0 || zone.y < boundY1 ||
                    zone.y > boundY2 || zone.y > boundY3)
                    continue;

                drawArrow(flowContext, zone, {x: zone.x + zone.u * 4, y: zone.y + zone.v * 4}, 5);

                // accumulate offset x
                offsetX += zone.u;
                offsetY += zone.v;
            }
            /**/

            renderSatisfyPatternShaper(flowContext, 0);

            /*
            var vecLen = Math.sqrt(offsetX*offsetX + offsetY*offsetY);
            if (vecLen != 0) {
                offsetX = offsetX / vecLen;
                offsetY = offsetY / vecLen;
            }
            else  {
                offsetX = offsetY = 0;
            }

            var OFFSET_PARM = 10.0;
            /*/
            var OFFSET_PARM = 0.04;
            /**/

            // Get C+ cluster
            bound2X0 = bound2X0 + offsetX*OFFSET_PARM;
            bound2X1 = bound2X1 + offsetX*OFFSET_PARM;
            bound2X2 = bound2X2 + offsetX*OFFSET_PARM;
            bound2X3 = bound2X3 + offsetX*OFFSET_PARM;

            bound2Y0 = bound2Y0 + offsetY*OFFSET_PARM;
            bound2Y1 = bound2Y1 + offsetY*OFFSET_PARM;
            bound2Y2 = bound2Y2 + offsetY*OFFSET_PARM;
            bound2Y3 = bound2Y3 + offsetY*OFFSET_PARM;

            //console.log("0: " + bound2X0 + " 1: " + bound2X1 + " 2: " + bound2X2 + " 3: " + bound2X3);
            //alert("");

            renderSmoothShape(flowContext);
        });

        webCamFlow.startCapture();
    }

    runFeatureMatching = function() {

        colsObject = imageObject.width;
        rowsObject = imageObject.height;

        colsScene = imageScene.width;
        rowsScene = imageScene.height;

        canvas.width = colsObject + colsScene;
        canvas.height = Math.max(rowsObject, rowsScene);
        var context = canvas.getContext('2d');
        context.drawImage(imageObject, 0, 0, imageObject.width, imageObject.height, 0, 0, colsObject, rowsObject);
        context.drawImage(imageScene, 0, 0, imageScene.width, imageScene.height, colsObject, 0, colsScene, rowsScene);

        var descriptorLength = 512;
        var matchesShown = 30;
        var blurRadius = 3;
        tracking.Fast.THRESHOLD = 30;
        tracking.Brief.N = descriptorLength;
        var imageDataObject = context.getImageData(0, 0, colsObject, rowsObject);
        var imageDataScene = context.getImageData(colsObject, 0, colsScene, rowsScene);

        var grayObject = tracking.Image.grayscale(tracking.Image.blur(imageDataObject.data, colsObject, rowsObject, blurRadius), colsObject, rowsObject);
        var grayScene = tracking.Image.grayscale(tracking.Image.blur(imageDataScene.data, colsScene, rowsScene, blurRadius), colsScene, rowsScene);

        var cornersObject = tracking.Fast.findCorners(grayObject, colsObject, rowsObject);
        var cornersScene = tracking.Fast.findCorners(grayScene, colsScene, rowsScene);

        var descriptorsObject = tracking.Brief.getDescriptors(grayObject, colsObject, cornersObject);
        var descriptorsScene = tracking.Brief.getDescriptors(grayScene, colsScene, cornersScene);

        var matches = tracking.Brief.reciprocalMatch(cornersObject, descriptorsObject, cornersScene, descriptorsScene);
        matches.sort(function (a, b) {
            return b.confidence - a.confidence;
        });

        //*
        for (var i = 0; i < Math.min(matchesShown, matches.length); i++) {
            var color = '#' + Math.floor(Math.random() * 16777215).toString(16);
            context.fillStyle = color;
            context.strokeStyle = color;
            context.fillRect(matches[i].keypoint1[0], matches[i].keypoint1[1], 5, 5);
            context.fillRect(matches[i].keypoint2[0] + colsObject, matches[i].keypoint2[1], 5, 5);
            context.beginPath();
            context.lineWidth = 3;
            context.moveTo(matches[i].keypoint1[0], matches[i].keypoint1[1]);
            context.lineTo(matches[i].keypoint2[0] + colsObject, matches[i].keypoint2[1]);
            context.stroke();
        }
        /**/

        find_transform(matches, matches.length);
        check_accurate_cluster(context, colsObject);
        render_pattern_shape(context, colsObject);
        renderSatisfyPatternShaper(context, colsObject);
    }

    window.onload = function () {

        runFeatureMatching();
        runOpticalFlow();
    }

    crossScriptMatching = function(image) {
        
        imageScene = image;

        runFeatureMatching();
    }

    // ------------------------------------------------------------------------
    // ------------------------------------------------------------------------

</script>

<script>

    // ------------------------------------------------------------------------
    // ------------------------------------------------------------------------
    // Camera canvas
    // ------------------------------------------------------------------------
    // ------------------------------------------------------------------------

    context = vcanvas.getContext('2d');

    // Grab elements, create settings, etc.
    var video = document.getElementById('video');
    //video.style.visibility = "hidden";

    this.c1 = document.getElementById("vcanvas");
    this.ctx1 = this.c1.getContext("2d");
    
    // Load image as augmented data
    var chickenOnMars = new Image();
    chickenOnMars.src = "../resources/superb_chicken_on_mars.png";

    // Get access to the camera!
    if(navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {

        /*
        // Not adding `{ audio: true }` since we only want video now
        navigator.mediaDevices.getUserMedia({ video: true }).then(function(stream) {
            //video.src = window.URL.createObjectURL(stream);
            video.srcObject = stream;
            video.play();
        });
        */
        computeFrame = function() {

            var image = this.video;
            var cols = image.width;
            var rows = image.height;
            vcanvas.width = cols;
            vcanvas.height = rows;
            context.drawImage(image, 0, 0, image.width, image.height, 0, 0, cols, rows);

            var imageData = context.getImageData(0, 0, cols, rows);
            var dataBuffer = new jsfeat.data_t(cols * rows, imageData.data.buffer);
            var mat = new jsfeat.matrix_t(cols, rows, jsfeat.U8_t | jsfeat.C4_t, dataBuffer);

            var gray = new jsfeat.matrix_t(mat.cols, mat.rows, jsfeat.U8_t | jsfeat.C1_t);
            jsfeat.imgproc.grayscale(mat.data, mat.cols, mat.rows, gray);

            this.ctx1.putImageData(matrix2img(gray), 0, 0);

            crossScriptMatching(image);

            // Todo: move this code block to the proper place
            //     This is just hotfix
            var oContext = overlay.getContext('2d');
            oContext.clearRect(0, 0, overlay.width, overlay.height);
            //renderSatisfyPatternShaper(oContext, 0);
            //renderSmoothShape(oContext);

            // Todo: move this code block to the proper place
            // Draw image on C+ cluster
            oContext.drawImage(chickenOnMars, bound2X0, bound2Y0, 
                                Math.abs(bound2X1 - bound2X0), 
                                Math.abs(bound2Y2 - bound2Y0));
        }
        
        timerCallback = function() {  
            if (this.video.paused || this.video.ended) {  
                return;  
            }  

            this.computeFrame();  
            var self = this;  

            setTimeout(function () {  
                self.timerCallback();  
            }, 16); // roughly 60 frames per second  
        }

        this.video.addEventListener("play", function() {
        
            self.width = self.video.width;  
            self.height = self.video.height; 
            self.timerCallback();
        
        }, false);
    }

</script>    

</body>
</html>